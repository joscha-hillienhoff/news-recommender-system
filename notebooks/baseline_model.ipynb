{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter, deque\n",
    "import time\n",
    "import json\n",
    "import zipfile\n",
    "from codecarbon import EmissionsTracker\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the absolute project root\n",
    "PROJ_ROOT = Path.cwd().parent \n",
    "\n",
    "# Define the interim data directory\n",
    "INTERIM_DIR = PROJ_ROOT / \"data\" / \"interim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_train = pd.read_parquet(INTERIM_DIR / \"behaviors_train.parquet\")\n",
    "news_train = pd.read_parquet(INTERIM_DIR / \"behaviors_train.parquet\")\n",
    "\n",
    "behaviors_val = pd.read_parquet(INTERIM_DIR / \"behaviors_val.parquet\")\n",
    "news_val = pd.read_parquet(INTERIM_DIR / \"news_val.parquet\")\n",
    "\n",
    "behaviors_test = pd.read_parquet(INTERIM_DIR / \"behaviors_test.parquet\")\n",
    "news_test = pd.read_parquet(INTERIM_DIR / \"news_test.parquet\")\n",
    "\n",
    "behaviors_train_val = pd.read_parquet(INTERIM_DIR / \"behaviors_train_val.parquet\")\n",
    "news_train_val = pd.read_parquet(INTERIM_DIR / \"news_train_val.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Carbon Emissions Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from news_recommender_system.carbon_tracking import CarbonTracker\n",
    "tracker = CarbonTracker(project_name=\"baseline\")\n",
    "tracker.start_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rolling window duration: 24 hours in seconds\n",
    "TIME_WINDOW = 86400\n",
    "\n",
    "# Dictionary to store clicked news articles with associated timestamps\n",
    "news_clicks = {}\n",
    "\n",
    "def update_news_clicks(current_time, past_clicked_articles):\n",
    "    \"\"\"\n",
    "    Update the news_clicks dictionary by removing outdated clicks and adding new ones.\n",
    "    \"\"\"\n",
    "    # Step 1: Remove old entries beyond the 24h time window\n",
    "    for news_id in list(news_clicks.keys()):\n",
    "        # Remove oldest click timestamps that fall outside the 24h window\n",
    "        while news_clicks[news_id] and news_clicks[news_id][0] < current_time - TIME_WINDOW:\n",
    "            news_clicks[news_id].popleft()\n",
    "        # Remove the entry if no clicks remain for this news_id\n",
    "        if not news_clicks[news_id]:\n",
    "            del news_clicks[news_id]\n",
    "\n",
    "    # Step 2: Add new clicks from the previous impression\n",
    "    if past_clicked_articles:\n",
    "        for news_id in past_clicked_articles[0]:\n",
    "            if news_id not in news_clicks:\n",
    "                news_clicks[news_id] = deque()\n",
    "            news_clicks[news_id].append(past_clicked_articles[1])  # Append the timestamp of the click\n",
    "\n",
    "\n",
    "def rank_news(user_impressions, current_time, past_clicked_articles):\n",
    "    \"\"\"\n",
    "    Rank news articles in the current impression based on the number of clicks \n",
    "    in the last 24 hours.\n",
    "    \"\"\"\n",
    "    # Update the global click stats with the current timestamp and past clicks\n",
    "    update_news_clicks(current_time, past_clicked_articles)\n",
    "\n",
    "    news_rank = []\n",
    "    for news_id in user_impressions:\n",
    "        if news_id in news_clicks:\n",
    "            # Use the number of clicks in the past 24h\n",
    "            news_rank.append((news_id, len(news_clicks[news_id])))\n",
    "        else:\n",
    "            # If no clicks, assign score of 0\n",
    "            news_rank.append((news_id, 0))\n",
    "\n",
    "    # Sort the news items by click count in descending order\n",
    "    news_rank.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return only the ordered list of news IDs\n",
    "    return [news_id for news_id, _ in news_rank]\n",
    "\n",
    "\n",
    "def rank_submission_format(user_impressions, current_time, past_clicked_articles):\n",
    "    \"\"\"\n",
    "    Return the ranking positions for each news article in the user impression list.\n",
    "    \"\"\"\n",
    "    ranked_news = rank_news(user_impressions, current_time, past_clicked_articles)\n",
    "    return [ranked_news.index(news_id) + 1 for news_id in user_impressions]\n",
    "\n",
    "\n",
    "def generate_prediction_file(behaviors_df, output_file=\"prediction.txt\"):\n",
    "    \"\"\"\n",
    "    Generate a prediction file with click-based news rankings for each impression.\n",
    "    \"\"\"\n",
    "    past_clicked_articles = []  # Stores clicked articles from the previous row\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for _, row in behaviors_df.iterrows():\n",
    "            impression_id = row['ImpressionId']\n",
    "            current_time = row['Timestamp']\n",
    "\n",
    "            # Extract only news IDs (without click label)\n",
    "            user_impressions = [news.split(\"-\")[0] for news in row['Impressions'].split()]\n",
    "\n",
    "            # Compute ranking positions based on past 24h click data\n",
    "            ranked_positions = rank_submission_format(user_impressions, current_time, past_clicked_articles)\n",
    "\n",
    "            # Write results to file in required format\n",
    "            f.write(f\"{impression_id} {json.dumps(ranked_positions)}\\n\")\n",
    "\n",
    "            # Prepare click data from this row for use in the next iteration\n",
    "            past_clicked_articles = (\n",
    "                [news.split(\"-\")[0] for news in row['Impressions'].split() if news.split(\"-\")[1] == '1'],\n",
    "                current_time\n",
    "            )\n",
    "\n",
    "    print(f\"✅ Prediction file '{output_file}' successfully created.\")\n",
    "\n",
    "\n",
    "# Generate predictions for the validation set using the click-based popularity model\n",
    "generate_prediction_file(behaviors_val, output_file=\"prediction_val_baseline.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carbon Emissions Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.end_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a truth file for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground truth file for validation set\n",
    "def generate_truth_file(validation_impressions, output_file=\"truth.txt\"):\n",
    "    \"\"\"\n",
    "    Generates a truth.txt file with ground truth click labels.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for impression_id, news_list in validation_impressions.items():\n",
    "            labels = [int(news.split(\"-\")[1]) for news in news_list]  # Click labels\n",
    "            f.write(f\"{impression_id} {json.dumps(labels)}\\n\")  # Format output\n",
    "\n",
    "    print(f\"✅ Truth file '{output_file}' successfully created.\")\n",
    "\n",
    "generate_truth_file(behaviors_val.set_index('ImpressionId')['Impressions'].apply(lambda x: x.split()), output_file=\"truth_val.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
